{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54c42c13-d1d4-4282-ba5f-cbab51f04b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30063d1d-5d6c-48c7-92ab-f7f4214d146f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shubham/goal_extraction/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "import re\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc833b2d-0eb1-496b-b53a-7b8820a100f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pdf reader object\n",
    "reader = PyPDF2.PdfReader('reports/training/adidas/2017.pdf')\n",
    "input_text = ''\n",
    "\n",
    "for i in reader.pages:\n",
    "    input_text += i.extract_text()\n",
    "\n",
    "input_text = input_text.replace('\\n', ' ')\n",
    "# input_text = 'At Bosch, diversity is a fundamental pillar. We ensured a diverse workforce by taking necessary measures in the past. Still, The company intends to increase workforce diversity by 40%. It would enable a healthy and balanced workforce that would be warm and welcoming for people from diverse backgrounds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a0411a-b194-4547-a3ff-1298f204b956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (956 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# First stage - Coreference Resolution\n",
    "coref_model = spacy.load('en_coreference_web_trf')\n",
    "doc = coref_model(input_text)\n",
    "\n",
    "def resolve_references(doc):\n",
    "    token_mention_mapper = {}\n",
    "    output_string = ''\n",
    "    clusters = [val for key, val in doc.spans.items() if key.startswith('coref_cluster')]\n",
    "\n",
    "    for cluster in clusters:\n",
    "        first_mention = cluster[0]\n",
    "\n",
    "        for mention_span in list(cluster)[1:]:\n",
    "            if len(mention_span) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                token_mention_mapper[mention_span[0].idx] = first_mention.text + mention_span[0].whitespace_\n",
    "                for token in mention_span[1:]:\n",
    "                    token_mention_mapper[token.idx] = ''\n",
    "\n",
    "    for token in doc:\n",
    "        if token.idx in token_mention_mapper:\n",
    "            output_string += token_mention_mapper[token.idx]\n",
    "        else:\n",
    "            output_string += token.text + token.whitespace_\n",
    "\n",
    "    return output_string\n",
    "\n",
    "resolved_string = resolve_references(doc)\n",
    "\n",
    "spacy_core = spacy.load('en_core_web_trf')\n",
    "doc = spacy_core(resolved_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f8fcb2-aa15-46ab-b0b9-e1eae847c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second and third stage - NER and POS tagging\n",
    "action_statements = list()\n",
    "flag = False\n",
    "list_of_sent = list(doc.sents)\n",
    "for sent in list_of_sent:\n",
    "    flag = False\n",
    "    sent = list(sent)\n",
    "    for word in sent:\n",
    "        if word.ent_type_ == 'ORG':\n",
    "            location = sent.index(word)\n",
    "            if (location+1 != len(sent)) and sent[location+1].tag_ in ('VB', 'VBG', 'VBP', 'VBZ', 'MD', 'VV', 'VP', 'VERB', 'VAFIN', 'VMFIN', 'VVFIN', 'VE'):\n",
    "                flag = True\n",
    "                break\n",
    "    if flag:\n",
    "        str_sent = list(map(lambda x: str(x), sent))\n",
    "        action_statements.append(' '.join(str_sent).replace(' - ', ' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d57bf3d4-bd5f-4ead-9684-1715929e8b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fourth stage - Inference\n",
    "# base_model = 'bert-base-uncased'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "# action_statements_tokenized = tokenizer(action_statements, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# class Dataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, encodings, labels=None):\n",
    "#         self.encodings = encodings\n",
    "#         self.labels = labels\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "#         if self.labels:\n",
    "#             item['labels'] = torch.tensor(self.labels[idx])\n",
    "#         return item\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.encodings['input_ids'])\n",
    "\n",
    "# test_dataset = Dataset(action_statements_tokenized)\n",
    "\n",
    "# model_path = 'checkpoint-1500'\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "# test_trainer = Trainer(model)\n",
    "\n",
    "\n",
    "# raw_pred, _, _ = test_trainer.predict(test_dataset)\n",
    "# y_pred = np.argmax(raw_pred, axis=1)\n",
    "\n",
    "# y_pred = pd.Series(y_pred)\n",
    "# goal_indices = list(y_pred[y_pred==1].index)\n",
    "\n",
    "# c = 1\n",
    "# for i in goal_indices:\n",
    "#     print(f'Goal{c}')\n",
    "#     print(action_statements[i])\n",
    "#     print('')\n",
    "#     c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e773f7bc-2847-400b-a31b-77de56d2d8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculating metrics\n",
    "# df = pd.read_csv('test_data.csv', sep=',')\n",
    "\n",
    "# def func(s):\n",
    "#     if s == 'Y':\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# df['is_goal'] = df['is_goal'].apply(func)\n",
    "\n",
    "# df = df.rename(columns={'is_goal': 'label'})\n",
    "\n",
    "\n",
    "# # Fourth stage - Inference\n",
    "# base_model = 'bert-base-uncased'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "# action_statements_tokenized = tokenizer(list(df['sentence']), padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# class Dataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, encodings, labels=None):\n",
    "#         self.encodings = encodings\n",
    "#         self.labels = labels\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "#         if self.labels:\n",
    "#             item['labels'] = torch.tensor(self.labels[idx])\n",
    "#         return item\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.encodings['input_ids'])\n",
    "\n",
    "# test_dataset = Dataset(action_statements_tokenized)\n",
    "\n",
    "# model_path = 'checkpoint-1500'\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "# test_trainer = Trainer(model)\n",
    "\n",
    "\n",
    "# raw_pred, _, _ = test_trainer.predict(test_dataset)\n",
    "# y_pred = np.argmax(raw_pred, axis=1)\n",
    "\n",
    "# y_pred = pd.Series(y_pred)\n",
    "# df['prediction'] = y_pred\n",
    "# # df.to_csv('df.csv', index=False)\n",
    "\n",
    "# print('Confusion Matrix: ')\n",
    "# print(confusion_matrix(df['label'], df['prediction']))\n",
    "# print(accuracy_score(df['label'], df['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ddb09d-a159-49cf-9a16-b62919a4422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.Series(action_statements)\n",
    "df.to_csv('temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43a15448-c726-42d3-838a-7b3d433b00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input_text = 'Diversity in workforce is important. We are aware that legal and cultural requirements can vary in a global market. Continental expects all of our suppliers to be guided by fairness, honesty and responsibility in all aspects of their business. Our supplier code establishes important standards that match the Continental corporate values. Every supplier must comply strictly with these standards. We use them to define requirements for good working conditions, then check compliance with these requirements through our on-site audits.'\n",
    "# input_text = 'A growing need for food, energy and clean water, limited resources and a booming world population â€“ reconciling all these factors is the greatest challenge of our time. Innovations based on chemistry play a key role here, as they contribute decisively to new solutions. Effective and efficient research and development is a prerequisite for innovation as well as an important growth engine for BASF. To ensure our long-term business success with chemistry-based solutions for almost all sectors of industry, we develop innovative processes and products for a sustainable future and drive forward digitalization in research worldwide.'\n",
    "# input_text = 'At Bosch, diversity is a fundamental pillar. We ensured a diverse workforce by taking necessary measures in the past. Still, The company intends to increase workforce diversity by 40%. It would enable a healthy and balanced workforce that would be warm and welcoming for people from diverse backgrounds.'\n",
    "# input_text = 'adidas increases sales for first time since the pandemic'\n",
    "# input_text = 'As a global financial institution, Deutsche Bank operates in various countries, each of which imposes its own regulations (often with extra- territorial implications). These define how we operate, as well as our conduct, behavior, and standards to which we must adhere. Our strategy and execution model is affected by different political environments and a large number of regulatory requirements. We remain continually aware of these forces that influence our business, and we engage in political and regulatory decisions. This is fundamental to understanding wider political developments and the evolution of the regulatory environment, as well as fostering stakeholder trust. In recent times, international and national political systems have shown signs of fragmentation. This directly affects our business model. In 2017 alone, we saw crucial elections in France, the UK, and Germany, as well as a new US government whose Con- gress passed a comprehensive tax reform that had an immediate impact on our US tax position. The UK has formally declared its exit from the EU, and negotiations are under way. This will have repercussions on our structure, operations, client relationships, and staffing. Furthermore, wider political developments in the Euro zone (such as important national elections) will impact the stability of financial markets, market prices, and long-term investment decisions by companies. All of this affects our entire value chain.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b570df0d-028c-42d9-85a3-da1402683c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second stage\n",
    "# ner_op_string = resolved_string\n",
    "# def show_ents(doc):\n",
    "#     global ner_op_string\n",
    "    \n",
    "#     if doc.ents:\n",
    "        \n",
    "#         for ent in doc.ents:\n",
    "#             # print(ent.text+' - ' +str(ent.start_char) +' - '+ str(ent.end_char) +' - '+ent.label_+ ' - '+str(spacy.explain(ent.label_)))\n",
    "            \n",
    "#             if ent.label_ == 'ORG':\n",
    "#                 word_length = ent.end_char - ent.start_char\n",
    "#                 ner_op_string = ner_op_string[:ent.start_char] + 'O'*(word_length) + ner_op_string[ent.end_char:]\n",
    "\n",
    "#     else:\n",
    "#         print('No named entities found.')\n",
    "    \n",
    "#     return ner_op_string\n",
    "# show_ents(doc)\n",
    "# ner_op_string = re.sub(r'O{2,}', 'ORG',ner_op_string)\n",
    "# print(ner_op_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08367d56-befa-49db-9974-cecea7a12af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(f'{token.text:{8}} {token.ent_type_:{8}} {token.pos_:{6}} {token.tag_:{6}} {token.dep_:{6}} {spacy.explain(token.pos_):{20}} {spacy.explain(token.tag_)}')\n",
    "# for token in doc:\n",
    "#     print(f'{token.text:{15}} {token.ent_type_:{8}} {token.pos_:{6}} {token.tag_:{6}}  {list(token.morph)}')\n",
    "\n",
    "# action_statements = list()\n",
    "# flag = False\n",
    "# list_of_sent = list(doc.sents)\n",
    "# for sent in list_of_sent:\n",
    "#     flag = False\n",
    "#     sent = list(sent)\n",
    "#     for word in sent:\n",
    "#         if word.ent_type_ == 'ORG':\n",
    "#             location = sent.index(word)\n",
    "#             if (location+1 != len(sent)) and sent[location+1].tag_ in ('VB', 'VBG', 'VBP', 'VBZ', 'MD', 'VV', 'VP', 'VERB', 'VAFIN', 'VMFIN', 'VVFIN', 'VE'):\n",
    "#                 flag = True\n",
    "#                 break\n",
    "#     if flag:\n",
    "#         str_sent = list(map(lambda x: str(x), sent))\n",
    "#         action_statements.append(' '.join(str_sent))\n",
    "# action_statements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
