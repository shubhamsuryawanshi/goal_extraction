{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54c42c13-d1d4-4282-ba5f-cbab51f04b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30063d1d-5d6c-48c7-92ab-f7f4214d146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "import re\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc833b2d-0eb1-496b-b53a-7b8820a100f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pdf reader object\n",
    "reader = PyPDF2.PdfReader('test/2019.pdf')\n",
    "input_text = ''\n",
    "\n",
    "for i in reader.pages:\n",
    "    input_text += i.extract_text()\n",
    "\n",
    "input_text = input_text.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44a0411a-b194-4547-a3ff-1298f204b956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /var/folders/lf/r0_x20qj11jc_bvp_yglr3700000gn/T/tmpn25w3dop/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/var/folders/lf/r0_x20qj11jc_bvp_yglr3700000gn/T/tmpn25w3dop/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (847 > 512). Running this sequence through the model will result in indexing errors\n",
      "loading configuration file /var/folders/lf/r0_x20qj11jc_bvp_yglr3700000gn/T/tmplqq5djj7/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/var/folders/lf/r0_x20qj11jc_bvp_yglr3700000gn/T/tmplqq5djj7/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "# First stage - Coreference Resolution\n",
    "coref_model = spacy.load('en_coreference_web_trf')\n",
    "doc = coref_model(input_text)\n",
    "\n",
    "def resolve_references(doc):\n",
    "    token_mention_mapper = {}\n",
    "    output_string = ''\n",
    "    clusters = [val for key, val in doc.spans.items() if key.startswith('coref_cluster')]\n",
    "\n",
    "    for cluster in clusters:\n",
    "        first_mention = cluster[0]\n",
    "\n",
    "        for mention_span in list(cluster)[1:]:\n",
    "            if len(mention_span) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                token_mention_mapper[mention_span[0].idx] = first_mention.text + mention_span[0].whitespace_\n",
    "                for token in mention_span[1:]:\n",
    "                    token_mention_mapper[token.idx] = ''\n",
    "\n",
    "    for token in doc:\n",
    "        if token.idx in token_mention_mapper:\n",
    "            output_string += token_mention_mapper[token.idx]\n",
    "        else:\n",
    "            output_string += token.text + token.whitespace_\n",
    "\n",
    "    return output_string\n",
    "\n",
    "resolved_string = resolve_references(doc)\n",
    "\n",
    "spacy_core = spacy.load('en_core_web_trf')\n",
    "doc = spacy_core(resolved_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70f8fcb2-aa15-46ab-b0b9-e1eae847c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second and third stage - NER and POS tagging\n",
    "action_statements = list()\n",
    "flag = False\n",
    "list_of_sent = list(doc.sents)\n",
    "for sent in list_of_sent:\n",
    "    flag = False\n",
    "    sent = list(sent)\n",
    "    for word in sent:\n",
    "        if word.ent_type_ == 'ORG':\n",
    "            location = sent.index(word)\n",
    "            if (location+1 != len(sent)) and sent[location+1].tag_ in ('VB', 'VBG', 'VBP', 'VBZ', 'MD', 'VV', 'VP', 'VERB', 'VAFIN', 'VMFIN', 'VVFIN', 'VE'):\n",
    "                flag = True\n",
    "                break\n",
    "    if flag:\n",
    "        str_sent = list(map(lambda x: str(x), sent))\n",
    "        action_statements.append(' '.join(str_sent).replace(' - ', ' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d57bf3d4-bd5f-4ead-9684-1715929e8b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/shubham/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/shubham/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
      "loading file tokenizer.json from cache at /Users/shubham/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/shubham/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/shubham/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file checkpoint-1000/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"checkpoint-1000\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file checkpoint-1000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoint-1000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 454\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal1\n",
      "That will not change going forward – ALLIANZ GROUP will continue to secure the future of ALLIANZ GROUP customers and society sustainably .\n",
      "\n",
      "Goal2\n",
      "the Encouraging Future Generations Program includes an ambition to increase the number of children and   youth benefited by 20 percent by 2020 ( baseline 2018 ) .\n",
      "\n",
      "Goal3\n",
      "ALLIANZ GROUP is committed to completely phasing out all coal based risks from P&C insurance portfolios by 2040 at the latest .\n",
      "\n",
      "Goal4\n",
      "ALLIANZ GROUP is working to provide more certainty to ALLIANZ GROUP customers on what level of cyber risk is covered by each insurance product .\n",
      "\n",
      "Goal5\n",
      "ALLIANZ GROUP are also improving ALLIANZ GROUP privacy cover to be as client orientated as possible .\n",
      "\n",
      "Goal6\n",
      "ALLIANZ GROUP aims to create a lasting positive legacy for society through ALLIANZ GROUP investments , believing that sustainable business practices improve the financial performance of companies .\n",
      "\n",
      "Goal7\n",
      "As a founding member of the U.N. convened Net Zero Asset Owner Alliance , ALLIANZ GROUP wants to ensure all asset managers are well prepared for the decarbonization of all asset managers portfolios in line with achieving a global average temperature increase of not more than 1.5 ° C.2 .\n",
      "\n",
      "Goal8\n",
      "ALLIANZ GROUP aims to measure and improve the ESG performance of ALLIANZ GROUP entire real estate portfolio .\n",
      "\n",
      "Goal9\n",
      "ALLIANZ GROUPtarget is to reach an the Global Investors for Sustainable Development Alliance ( GISD ) initiative score   of 73 percent by 2021 .\n",
      "\n",
      "Goal10\n",
      "ALLIANZ GROUP is working to bring greater transparency to job roles and capabilities by developing a common global language and understanding of roles .\n",
      "\n",
      "Goal11\n",
      "ALLIANZ GROUP aims to provide a productive and health promoting workplace and enables ALLIANZ GROUP employees to foster health and avoid work related stress .\n",
      "\n",
      "Goal12\n",
      "To accomplish enhancing , ALLIANZ GROUP aim to ensure that robust privacy controls are embedded in a privacy focused culture , which support well designed processing activities .\n",
      "\n",
      "Goal13\n",
      "ALLIANZ GROUP aim at publishing all customer feedback online for full transparency , visible to ALLIANZ GROUP customers and prospective customers .\n",
      "\n",
      "Goal14\n",
      "ALLIANZ GROUP has committed to reduce GHG emissions by 30 percent per employee by 2019 , against a 2018 baseline .\n",
      "\n",
      "Goal15\n",
      "ALLIANZ GROUPtarget is to reduce paper use by 40 percent per policy by 2018 against a 2014 baseline .\n",
      "\n",
      "Goal16\n",
      "ENV–7).WASTEWe seek to minimize the waste ALLIANZ GROUP generate and to re use or recycle materials wherever possible ( see   Table ENV–8 ) .   ALLIANZ GROUP employees also actively support local clean up activities .\n",
      "\n",
      "Goal17\n",
      "For 2020 , ALLIANZ GROUP aim to set public long term and intermediary climate targets for ALLIANZ GROUP proprietary investments and business operations in line with the Paris Agreement goal to limit global warming to 1.5 ° C .\n",
      "\n",
      "Goal18\n",
      "Members of the UN convened Net Zero Asset Owner Alliance commit to reduce GHG emissions of Members of the AOA proprietary investment portfolios to net zero by 2050 .\n",
      "\n",
      "Goal19\n",
      "By leveraging the expertise of several units and departments , ALLIANZ GROUP want to create an impact in the real economy and encourage companies to define and implement climate strategies following scientific findings .\n",
      "\n",
      "Goal20\n",
      "By actively encouraging companies to set measurable climate targets that are transparently pursued ,   for example by joining SOS Children ’s Villages , ALLIANZ GROUP aim to not only reduce emissions in ALLIANZ GROUP proprietary investment portfolio but eventually in the real world .\n",
      "\n",
      "Goal21\n",
      "ALLIANZ GROUP are continuously improving the inclusion of global natural catastrophe hazard information , including climate , into underwriting decisions.05.5.3\n",
      "\n",
      "Goal22\n",
      "To this end , ALLIANZ GROUP will set ALLIANZ GROUP long term and intermediary emissions reduction targets for ALLIANZ GROUP business operations as well as The emerging consumers ’ market in line with the Paris Agreement target of limiting global warming to 1.5 ° C .\n",
      "\n",
      "Goal23\n",
      "the U.N.-Convened Net Zero Asset Owner Alliance is also striving to have engagement related targets .\n",
      "\n",
      "Goal24\n",
      "Raised ALLIANZ GROUP carbon reduction target ambition to align with 1.5 ° C compatible pathways.• Set long term and intermediary climate targets ( 2025 ) for proprietary investments in line with 1.5ºC as soon as Net Zero Asset Owner Alliance has defined framework for   target setting ( expected for Q4 2020)•\n",
      "\n",
      "Goal25\n",
      "Together with the Principles for Responsible Investment ( PRI , ALLIANZ GROUP will furthermore develop new approaches on climate risk assessment tools for the insurance industry .\n",
      "\n",
      "Goal26\n",
      "Achieved a share of 49 % green electricity of total electricity used ( 2018 : 45 % ) within ALLIANZ GROUP Achieve 100 % green electricity for our operations by 2023 within ALLIANZ GROUP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fourth stage - Inference\n",
    "base_model = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "action_statements_tokenized = tokenizer(action_statements, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "test_dataset = Dataset(action_statements_tokenized)\n",
    "\n",
    "model_path = \"checkpoint-1000\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "test_trainer = Trainer(model)\n",
    "\n",
    "\n",
    "raw_pred, _, _ = test_trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(raw_pred, axis=1)\n",
    "\n",
    "y_pred = pd.Series(y_pred)\n",
    "goal_indices = list(y_pred[y_pred==1].index)\n",
    "\n",
    "c = 1\n",
    "for i in goal_indices:\n",
    "    print(f'Goal{c}')\n",
    "    print(action_statements[i])\n",
    "    print('')\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29ddb09d-a159-49cf-9a16-b62919a4422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.Series(action_statements)\n",
    "# df.to_csv('temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43a15448-c726-42d3-838a-7b3d433b00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input_text = 'Diversity in workforce is important. We are aware that legal and cultural requirements can vary in a global market. Continental expects all of our suppliers to be guided by fairness, honesty and responsibility in all aspects of their business. Our supplier code establishes important standards that match the Continental corporate values. Every supplier must comply strictly with these standards. We use them to define requirements for good working conditions, then check compliance with these requirements through our on-site audits.'\n",
    "# input_text = 'A growing need for food, energy and clean water, limited resources and a booming world population – reconciling all these factors is the greatest challenge of our time. Innovations based on chemistry play a key role here, as they contribute decisively to new solutions. Effective and efficient research and development is a prerequisite for innovation as well as an important growth engine for BASF. To ensure our long-term business success with chemistry-based solutions for almost all sectors of industry, we develop innovative processes and products for a sustainable future and drive forward digitalization in research worldwide.'\n",
    "# input_text = 'At Bosch, diversity is a fundamental pillar. We ensured a diverse workforce by taking necessary measures in the past. Still, The company intends to increase workforce diversity by 40%. It would enable a healthy and balanced workforce that would be warm and welcoming for people from diverse backgrounds.'\n",
    "# input_text = 'adidas increases sales for first time since the pandemic'\n",
    "# input_text = 'As a global financial institution, Deutsche Bank operates in various countries, each of which imposes its own regulations (often with extra- territorial implications). These define how we operate, as well as our conduct, behavior, and standards to which we must adhere. Our strategy and execution model is affected by different political environments and a large number of regulatory requirements. We remain continually aware of these forces that influence our business, and we engage in political and regulatory decisions. This is fundamental to understanding wider political developments and the evolution of the regulatory environment, as well as fostering stakeholder trust. In recent times, international and national political systems have shown signs of fragmentation. This directly affects our business model. In 2017 alone, we saw crucial elections in France, the UK, and Germany, as well as a new US government whose Con- gress passed a comprehensive tax reform that had an immediate impact on our US tax position. The UK has formally declared its exit from the EU, and negotiations are under way. This will have repercussions on our structure, operations, client relationships, and staffing. Furthermore, wider political developments in the Euro zone (such as important national elections) will impact the stability of financial markets, market prices, and long-term investment decisions by companies. All of this affects our entire value chain.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b570df0d-028c-42d9-85a3-da1402683c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second stage\n",
    "# ner_op_string = resolved_string\n",
    "# def show_ents(doc):\n",
    "#     global ner_op_string\n",
    "    \n",
    "#     if doc.ents:\n",
    "        \n",
    "#         for ent in doc.ents:\n",
    "#             # print(ent.text+' - ' +str(ent.start_char) +' - '+ str(ent.end_char) +' - '+ent.label_+ ' - '+str(spacy.explain(ent.label_)))\n",
    "            \n",
    "#             if ent.label_ == 'ORG':\n",
    "#                 word_length = ent.end_char - ent.start_char\n",
    "#                 ner_op_string = ner_op_string[:ent.start_char] + 'O'*(word_length) + ner_op_string[ent.end_char:]\n",
    "\n",
    "#     else:\n",
    "#         print('No named entities found.')\n",
    "    \n",
    "#     return ner_op_string\n",
    "# show_ents(doc)\n",
    "# ner_op_string = re.sub(r'O{2,}', 'ORG',ner_op_string)\n",
    "# print(ner_op_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a7aadc3-92a3-4ed0-bae8-f5a3678a8067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_action_statements(ner_op_string):\n",
    "#     temp_list = ner_op_string.split('. ')\n",
    "#     return '. '.join(list(filter(lambda x: 'ORG' in x, temp_list)))\n",
    "\n",
    "# print(get_org_sentences(ner_op_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20c55cff-db09-44b6-8b2c-94fadf68fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(f'{token.text:{8}} {token.ent_type_:{8}} {token.pos_:{6}} {token.tag_:{6}} {token.dep_:{6}} {spacy.explain(token.pos_):{20}} {spacy.explain(token.tag_)}')\n",
    "# for token in doc:\n",
    "#     print(f'{token.text:{15}} {token.ent_type_:{8}} {token.pos_:{6}} {token.tag_:{6}}  {list(token.morph)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08367d56-befa-49db-9974-cecea7a12af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# action_statements = list()\n",
    "# flag = False\n",
    "# list_of_sent = list(doc.sents)\n",
    "# for sent in list_of_sent:\n",
    "#     flag = False\n",
    "#     sent = list(sent)\n",
    "#     for word in sent:\n",
    "#         if word.ent_type_ == 'ORG':\n",
    "#             location = sent.index(word)\n",
    "#             if (location+1 != len(sent)) and sent[location+1].tag_ in ('VB', 'VBG', 'VBP', 'VBZ', 'MD', 'VV', 'VP', 'VERB', 'VAFIN', 'VMFIN', 'VVFIN', 'VE'):\n",
    "#                 flag = True\n",
    "#                 break\n",
    "#     if flag:\n",
    "#         str_sent = list(map(lambda x: str(x), sent))\n",
    "#         action_statements.append(' '.join(str_sent))\n",
    "# action_statements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "25bdac3ce80f51322238444d1c3aee85694d9fc1f29af57a73a70ccd6f0c6c1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
